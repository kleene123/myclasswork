# 参考文献

## 核心论文

### Transformer 架构

[1] **Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I.** (2017). *Attention is all you need*. Advances in neural information processing systems, 30.

- 提出了 Transformer 架构
- 引入自注意力机制
- NLP 领域的里程碑工作

[2] **Devlin, J., Chang, M. W., Lee, K., & Toutanova, K.** (2018). *BERT: Pre-training of deep bidirectional transformers for language understanding*. arXiv preprint arXiv:1810.04805.

- 提出 BERT 预训练模型
- 双向 Transformer 编码器
- 在多个 NLP 任务上取得突破

### 模型量化

[3] **Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., ... & Kalenichenko, D.** (2018). *Quantization and training of neural networks for efficient integer-arithmetic-only inference*. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2704-2713).

- INT8 量化的奠基性工作
- 提出量化感知训练
- Google 的量化白皮书

[4] **Krishnamoorthi, R.** (2018). *Quantizing deep convolutional networks for efficient inference: A whitepaper*. arXiv preprint arXiv:1806.08342.

- Facebook 的量化白皮书
- 系统介绍量化方法
- 工业界实践经验

### BERT 量化

[5] **Zafrir, O., Boudoukh, G., Izsak, P., & Wasserblat, M.** (2019). *Q8BERT: Quantized 8bit BERT*. In 2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS Edition (EMC2-NIPS) (pp. 36-39). IEEE.

- 首个 BERT 的 8 比特量化方案
- 实现了 4 倍压缩
- 准确率损失小于 1%

[6] **Shen, S., Dong, Z., Ye, J., Ma, L., Yao, Z., Gholami, A., ... & Keutzer, K.** (2020). *Q-BERT: Hessian based ultra low precision quantization of BERT*. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 05, pp. 8815-8821).

- 基于 Hessian 的量化方法
- 实现超低精度量化
- 理论分析深入

[7] **Zhang, W., Hou, L., Yin, Y., Shang, L., Chen, X., Jiang, X., & Liu, Q.** (2020). *TernaryBERT: Distillation-aware ultra-low bit BERT*. arXiv preprint arXiv:2009.12812.

- 三值量化 BERT
- 结合知识蒸馏
- 极致压缩

[8] **Bai, H., Zhang, W., Hou, L., Shang, L., Jin, J., Jiang, X., ... & Lyu, M. R.** (2021). *BinaryBERT: Pushing the limit of BERT quantization*. arXiv preprint arXiv:2012.15701.

- 二值化 BERT
- 推向量化极限
- 理论与实践结合

### 量化综述

[9] **Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M. W., & Keutzer, K.** (2021). *A survey of quantization methods for efficient neural network inference*. arXiv preprint arXiv:2103.13630.

- 量化技术全面综述
- 覆盖各种量化方法
- 实践指导价值高

[10] **Nagel, M., Fournarakis, M., Amjad, R. A., Bondarenko, Y., Van Baalen, M., & Blankevoort, T.** (2021). *A white paper on neural network quantization*. arXiv preprint arXiv:2106.08295.

- Qualcomm 的量化白皮书
- 工业界视角
- 实用性强

## 技术文档

### PyTorch

[11] **PyTorch Quantization Documentation**
https://pytorch.org/docs/stable/quantization.html

- PyTorch 官方量化文档
- 包含动态、静态、QAT 等方法
- 代码示例丰富

[12] **PyTorch Quantization Tutorial**
https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html

- 官方量化教程
- 逐步指导
- 实践性强

### Transformers

[13] **Hugging Face Transformers Documentation**
https://huggingface.co/docs/transformers/

- Transformers 库官方文档
- BERT 等模型的使用
- 社区活跃

[14] **Hugging Face Optimum**
https://huggingface.co/docs/optimum/

- 模型优化工具库
- 包含量化、剪枝等
- 与 Transformers 集成

## 相关工具和库

### 量化工具

[15] **ONNX Runtime Quantization**
https://onnxruntime.ai/docs/performance/quantization.html

- ONNX 格式的量化
- 跨平台部署
- 性能优化

[16] **TensorFlow Model Optimization**
https://www.tensorflow.org/model_optimization

- TensorFlow 的优化工具包
- 包含量化、剪枝等
- Google 官方支持

[17] **Intel Neural Compressor**
https://github.com/intel/neural-compressor

- Intel 的神经网络压缩工具
- 针对 Intel 硬件优化
- 自动化量化

### 模型压缩

[18] **Hinton, G., Vinyals, O., & Dean, J.** (2015). *Distilling the knowledge in a neural network*. arXiv preprint arXiv:1503.02531.

- 知识蒸馏的经典论文
- 模型压缩的重要方法
- 理论基础

[19] **Han, S., Mao, H., & Dally, W. J.** (2015). *Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding*. arXiv preprint arXiv:1510.00149.

- 综合压缩方法
- 剪枝+量化+编码
- 极致压缩

## 数据集

[20] **Maas, A., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C.** (2011). *Learning word vectors for sentiment analysis*. In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies (pp. 142-150).

- IMDB 数据集论文
- 情感分析基准
- 广泛使用

[21] **Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R.** (2018). *GLUE: A multi-task benchmark and analysis platform for natural language understanding*. arXiv preprint arXiv:1804.07461.

- GLUE 基准测试集
- 多任务评估
- NLP 标准基准

## 在线资源

### 博客文章

[22] **Quantization in Deep Learning**
https://leimao.github.io/article/Neural-Networks-Quantization/

- 量化技术详细介绍
- 图文并茂
- 易于理解

[23] **A Gentle Introduction to Neural Network Quantization**
https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/

- 量化入门教程
- TensorFlow 示例
- 实践导向

### 视频教程

[24] **Neural Network Quantization - CS231n**
https://www.youtube.com/watch?v=...

- Stanford 课程
- 系统讲解
- 学术权威

[25] **Practical Quantization in PyTorch**
https://www.youtube.com/watch?v=...

- PyTorch 官方教程
- 实用性强
- 代码示例

## 硬件相关

[26] **ARM NEON and VFP Programming**
https://developer.arm.com/

- ARM 处理器优化
- NEON 指令集
- 移动端部署

[27] **Intel AVX-512 Deep Learning Boost**
https://www.intel.com/content/www/us/en/developer/articles/

- Intel CPU 加速
- VNNI 指令
- 服务器端优化

## 补充资料

### 实验工具

[28] **Weights & Biases**
https://wandb.ai/

- 实验跟踪工具
- 可视化结果
- 团队协作

[29] **TensorBoard**
https://www.tensorflow.org/tensorboard

- 训练可视化
- 指标监控
- Google 出品

### Python 库

[30] **NumPy Documentation**
https://numpy.org/doc/

- 数值计算基础库
- 数组操作
- 科学计算

[31] **Pandas Documentation**
https://pandas.pydata.org/docs/

- 数据分析库
- 表格处理
- 数据可视化

[32] **Matplotlib Documentation**
https://matplotlib.org/

- 绘图库
- 图表生成
- 科学可视化

[33] **Seaborn Documentation**
https://seaborn.pydata.org/

- 统计可视化
- 高级绘图
- 美观图表

## 学术会议

- **NeurIPS**: Neural Information Processing Systems
- **ICML**: International Conference on Machine Learning
- **ICLR**: International Conference on Learning Representations
- **ACL**: Association for Computational Linguistics
- **EMNLP**: Empirical Methods in Natural Language Processing
- **CVPR**: Computer Vision and Pattern Recognition

## 延伸阅读

[34] **Goodfellow, I., Bengio, Y., & Courville, A.** (2016). *Deep learning*. MIT press.

- 深度学习经典教材
- 理论基础全面
- 必读书籍

[35] **Jurafsky, D., & Martin, J. H.** (2020). *Speech and language processing* (3rd ed. draft).

- NLP 经典教材
- 理论与实践结合
- 在线免费

---

**说明**：以上参考文献按照学术规范格式整理，包含了 Transformer 模型、模型量化、BERT 量化等相关的重要论文和资源。在撰写课程设计报告时，应根据实际引用情况选择相关文献。
